<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="generator" content="Hugo 0.88.1" />
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
	<link rel="stylesheet" href=""https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
	<link rel="stylesheet" href="css/custom.css">
	<link rel="stylesheet" href="css/normalize.css">

	<title>Medical Sora</title>
	<link href="css/bootstrap.min.css" rel="stylesheet">

	<style>
        .highlight {
            background-color: #7CFC00; /* ËÆæÁΩÆÈÜíÁõÆÁöÑËÉåÊôØ */
            color: black; /* ÊñáÂ≠óÈ¢úËâ≤‰∏∫ÁôΩËâ≤ */
            padding: 15px; /* Ê∑ªÂä†ÂÜÖËæπË∑ùÔºå‰ΩøÂÜÖÂÆπÊõ¥ËàíÈÄÇ */
            border-radius: 15px; /* ÂúÜËßíÊïàÊûúÔºåÂçäÂæÑ15px */
            font-weight: bold; /* ÊñáÂ≠óÂä†Á≤ó */
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); /* Ê∑ªÂä†Èò¥ÂΩ±ÊïàÊûú */
        }
    </style>
</head>


<body data-new-gr-c-s-check-loaded="14.1091.0" data-gr-ext-installed="">

<div class="container" >
<header role="banner">
</header>
<main role="main">
<article itemscope itemtype="https://schema.org/BlogPosting">

	
<div class="container pt-5 mt-5 shadow-lg p-5 mb-5 bg-white rounded">
	<div class="highlight">
        	üîä The work is still under construction.
    	</div>
	<br>
	
	<div class="text-center">
	<h2>Medical Sora: Towards A Medical World Simulator with Generalist Medical Video Generation</h2>

      [<a href="https://arxiv.org/">Paper</a>]
      [<a href="https://github.com/">Code</a>]
      [<a href="https://huggingface.co/">Model</a>]
      [<a href="https://huggingface.co/">Data</a>]

        <p class="fst-italic mb-0">
			<br>
			Benyou Wang Team
		<p></p>
        </p>
        <p><b>The Chinese University of Hong Kong, Shenzhen</b></p>
	</div>
	<p><b>Abstract:</b>
	In this work, we present <b>Medical Sora</b>, a general-purpose video generation model designed for the medical field. Medical Sora aims to assist medical education, clinical training, and medical simulations by generating realistic medical videos. The model leverages state-of-the-art deep learning technologies and is capable of automatically generating videos of various medical scenarios, surgical procedures, diagnostic workflows, and more, covering a broad range of medical knowledge and skills. Trained on a large dataset of medical information, Medical Sora not only generates high-quality videos but also ensures the accuracy and professionalism of the medical content, enabling healthcare professionals to practice and learn repeatedly without the need for hands-on procedures.	
	<p style="text-align: center;">
		<img src="pics/CosyVoice2-overview.png" height="400" width="1024">
	</p>
<body>
</body>

</p>
	</p>

	<p>
	<b>Contents</b>
      <ul><li><a href="#Main Results">Main Results</a></li>
	      <ul>
			<li><a href="#Videoscore">Videoscore</a></li>
		        <li><a href="#VBench">VBench</a></li>
		</ul>
	<li><a href="#Demo">Demo</a></li>
	</p>

</div>

<div class="container pt-5 mt-5 shadow-lg p-5 mb-5 bg-white rounded">
	<h2 id="Main Results" style="text-align: center;">Main Results</h2>

	<h3 id="Videoscore" style="text-align: left;">Videoscore</h3>
		<p>VideoScore is an end-to-end video generation evaluation framework trained on the carefully curated VideoFeedback dataset. It comprehensively evaluates videos across five key dimensions: visual quality, temporal consistency, dynamic degree, text-to-video alignment, and factual consistency. In multiple benchmark tests, VideoScore significantly outperforms baseline models such as GPT-4 and Gemini 1.5. As an automated video evaluation tool, VideoScore not only accurately assesses video quality but also effectively simulates human feedback on generated videos. Although many models achieve high image quality, they often suffer from noticeable distortions. Therefore, we also evaluate the Distortion Rate, which is determined through human assessment.</p>
		<div class="table-responsive pt-3">
			<style>
			  .comparison-table {
			    width: 100%;
			    border-collapse: collapse;
			    font-family: Arial, sans-serif;
			    margin: 20px 0;
			    overflow-x: auto;
			    display: block;
			  }
			
			  .comparison-table th,
			  .comparison-table td {
			    padding: 12px;
			    text-align: center;
			    border: 1px solid #ddd;
			  }
			
			  .comparison-table th {
			    background-color: #f5f5f5;
			    font-weight: bold;
			    white-space: nowrap;
			  }
			
			  .comparison-table tr:nth-child(even) {
			    background-color: #fafafa;
			  }
			
			  .comparison-table tr:hover {
			    background-color: #f0f0f0;
			  }
			
			  .section-header {
			    background-color: #eef2f5 !important;
			    font-weight: bold;
			    text-align: center !important;
			  }
			
			  .model-name {
			    text-align: left;
			    white-space: nowrap;
			  }
			
			  /* ‰∏∫Distortion RateÂàóÊ∑ªÂä†ÁâπÊÆäÊ†∑Âºè */
			  .comparison-table td:last-child,
			  .comparison-table th:last-child {
			    border: 2px solid #666;
			    background-color: rgba(0, 0, 0, 0.02);
			  }
			
			  /* ÂìçÂ∫îÂºèËÆæËÆ° */
			  @media screen and (max-width: 768px) {
			    .comparison-table {
			      font-size: 14px;
			    }
			    
			    .comparison-table th,
			    .comparison-table td {
			      padding: 8px;
			    }
			  }
			</style>
			
			<table class="comparison-table">
			  <tr>
			    <th>Model</th>
			    <th>Visual Quality ‚Üë</th>
			    <th>Temporal Consistency ‚Üë</th>
			    <th>Dynamic Degree ‚Üë</th>
			    <th>Text-to-Video Alignment ‚Üë</th>
			    <th>Factual Consistency ‚Üë</th>
			    <th>Distortion Rate ‚Üì</th>
			  </tr>
			  <tr>
			    <td colspan="7" class="section-header">Open-source video generation model</td>
			  </tr>
			  <tr>
			    <td class="model-name">CogVideoX-2B</td>
			    <td>3.35</td>
			    <td>3.21</td>
			    <td>3.36</td>
			    <td>3.13</td>
			    <td>3.09</td>
			    <td>88.00</td>
			  </tr>
			  <tr>
			    <td class="model-name">CogVideoX-5B</td>
			    <td>3.30</td>
			    <td>3.13</td>
			    <td>3.33</td>
			    <td>3.07</td>
			    <td>3.03</td>
			    <td>80.00</td>
			  </tr>
			  <tr>
			    <td class="model-name">Open Sora (v1.2)</td>
			    <td>3.21</td>
			    <td>3.04</td>
			    <td>3.24</td>
			    <td>2.97</td>
			    <td>2.93</td>
			    <td>99.50</td>
			  </tr>
			  <tr>
			    <td class="model-name">Open Sora Plan (v1.3)</td>
			    <td>3.39</td>
			    <td>3.29</td>
			    <td>3.32</td>
			    <td>3.13</td>
			    <td>3.18</td>
			    <td>93.03</td>
			  </tr>
			  <tr>
			    <td class="model-name">VideoCrafter-2</td>
			    <td>2.91</td>
			    <td>2.78</td>
			    <td>3.10</td>
			    <td>2.80</td>
			    <td>2.64</td>
			    <td>97.00</td>
			  </tr>
			  <tr>
			    <td class="model-name">ModelScope</td>
			    <td>2.86</td>
			    <td>2.72</td>
			    <td>3.10</td>
			    <td>2.77</td>
			    <td>2.58</td>
			    <td>100.00</td>
			  </tr>
			  <tr>
			    <td class="model-name">Latte-1</td>
			    <td>3.08</td>
			    <td>2.87</td>
			    <td>3.17</td>
			    <td>2.91</td>
			    <td>2.76</td>
			    <td>97.50</td>
			  </tr>
			  <tr>
			    <td class="model-name">Vchitect-2.0</td>
			    <td>2.94</td>
			    <td>2.80</td>
			    <td>3.14</td>
			    <td>2.82</td>
			    <td>2.67</td>
			    <td>99.50</td>
			  </tr>
			  <tr>
			    <td class="model-name">Pyramid-Flow</td>
			    <td>2.87</td>
			    <td>2.74</td>
			    <td>3.08</td>
			    <td>2.76</td>
			    <td>2.60</td>
			    <td>98.50</td>
			  </tr>
			  <tr>
			    <td class="model-name">Allegro</td>
			    <td>3.28</td>
			    <td>3.12</td>
			    <td>3.17</td>
			    <td>2.82</td>
			    <td>3.06</td>
			    <td>93.50</td>
			  </tr>
			  <tr>
			    <td class="model-name">Mochi-1-preview</td>
			    <td>3.03</td>
			    <td>2.84</td>
			    <td>3.13</td>
			    <td>2.84</td>
			    <td>2.73</td>
			    <td>83.50</td>
			  </tr>
			  <tr>
			    <td class="model-name">LTX-Video</td>
			    <td>3.01</td>
			    <td>2.83</td>
			    <td>3.10</td>
			    <td>2.83</td>
			    <td>2.71</td>
			    <td>100.00</td>
			  </tr>
			  <tr>
			    <td class="model-name">HunyuanVideo</td>
			    <td>3.16</td>
			    <td>3.01</td>
			    <td>3.02</td>
			    <td>2.82</td>
			    <td>2.91</td>
			    <td>45.00</td>
			  </tr>
			  <tr>
			    <td colspan="7" class="section-header">Commercial video generation model</td>
			  </tr>
			  <tr>
			    <td class="model-name">Kling</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			  </tr>
			  <tr>
			    <td class="model-name">Hailuo</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			  </tr>
			  <tr>
			    <td class="model-name">Sora</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			  </tr>
			  <tr>
			    <td colspan="7" class="section-header">Our model</td>
			  </tr>
			  <tr>
			    <td class="model-name"><strong>Medical Sora (ours)</strong></td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			    <td>-</td>
			  </tr>
			</table>
		</div>
	<h3 id="VBench" style="text-align: left;">VBench</h3>
		<p>To evaluate the performance of text-to-video generation, we adopted multiple evaluation metrics that align with human perception, which are also used in Vbench. These include: (1) <b>Subject Consistency</b>, to assess the consistency of the video's subject appearance; (2) <b>Background Consistency</b>, to evaluate the temporal consistency of the video's background; (3) <b>Motion Smoothness</b>, to measure the smoothness of the generated motion; (4) <b>Dynamic Degree</b>, to assess whether the video contains large-scale movements; (5) <b>Aesthetic Quality</b>, to evaluate the aesthetic quality of the video (aesthetic scoring can be ignored for medical videos); and (6) <b>Imaging Quality</b>, to assess the overall imaging quality of the video. Although many models achieve high image quality, they often suffer from noticeable distortions. Therefore, we also evaluate the <b>Distortion Rate</b>, which is determined through human assessment.</p>
		<div class="table-responsive pt-3">
		<table class="comparison-table">
		  <tr>
		    <th>Model</th>
		    <th>Subject Consistency ‚Üë</th>
		    <th>Background Consistency ‚Üë</th>
		    <th>Motion Smoothness ‚Üë</th>
		    <th>Dynamic Degree ‚Üë</th>
		    <th>Aesthetic Quality ‚Üë</th>
		    <th>Imaging Quality ‚Üë</th>
		    <th>Distortion Rate ‚Üì</th>
		  </tr>
		  <tr>
		    <td colspan="8" class="section-header">Open-source video generation model</td>
		  </tr>
		  <tr>
		    <td class="model-name">CogVideoX-2B</td>
		    <td>94.03</td>
		    <td>95.01</td>
		    <td>98.04</td>
		    <td>71.50</td>
		    <td>44.17</td>
		    <td>61.22</td>
		    <td>88.00</td>
		  </tr>
		  <tr>
		    <td class="model-name">CogVideoX-5B</td>
		    <td>93.92</td>
		    <td>96.04</td>
		    <td>98.13</td>
		    <td>63.00</td>
		    <td>42.61</td>
		    <td>56.10</td>
		    <td>80.00</td>
		  </tr>
		  <tr>
		    <td class="model-name">Open Sora (v1.2)</td>
		    <td>95.40</td>
		    <td>96.46</td>
		    <td>99.40</td>
		    <td>26.00</td>
		    <td>46.25</td>
		    <td>64.88</td>
		    <td>99.50</td>
		  </tr>
		  <tr>
		    <td class="model-name">Open Sora Plan (v1.3)</td>
		    <td>97.08</td>
		    <td>97.38</td>
		    <td>99.33</td>
		    <td>22.00</td>
		    <td>45.96</td>
		    <td>67.60</td>
		    <td>93.03</td>
		  </tr>
		  <tr>
		    <td class="model-name">VideoCrafter-2</td>
		    <td>98.13</td>
		    <td>98.42</td>
		    <td>98.53</td>
		    <td>23.00</td>
		    <td>54.48</td>
		    <td>70.52</td>
		    <td>97.00</td>
		  </tr>
		  <tr>
		    <td class="model-name">ModelScope</td>
		    <td>92.99</td>
		    <td>96.24</td>
		    <td>96.43</td>
		    <td>45.50</td>
		    <td>42.20</td>
		    <td>63.99</td>
		    <td>100.00</td>
		  </tr>
		  <tr>
		    <td class="model-name">Latte-1</td>
		    <td>96.41</td>
		    <td>96.75</td>
		    <td>98.09</td>
		    <td>47.50</td>
		    <td>49.39</td>
		    <td>69.87</td>
		    <td>97.50</td>
		  </tr>
		  <tr>
		    <td class="model-name">Vchitect-2.0</td>
		    <td>88.07</td>
		    <td>93.50</td>
		    <td>93.89</td>
		    <td>80.00</td>
		    <td>42.01</td>
		    <td>63.02</td>
		    <td>99.50</td>
		  </tr>
		  <tr>
		    <td class="model-name">Pyramid-Flow</td>
		    <td>91.54</td>
		    <td>94.75</td>
		    <td>99.38</td>
		    <td>46.50</td>
		    <td>45.71</td>
		    <td>67.41</td>
		    <td>98.50</td>
		  </tr>
		  <tr>
		    <td class="model-name">Allegro</td>
		    <td>92.96</td>
		    <td>95.16</td>
		    <td>99.01</td>
		    <td>49.50</td>
		    <td>47.60</td>
		    <td>72.22</td>
		    <td>93.50</td>
		  </tr>
		  <tr>
		    <td class="model-name">Mochi-1-preview</td>
		    <td>92.51</td>
		    <td>94.60</td>
		    <td>99.08</td>
		    <td>77.50</td>
		    <td>44.33</td>
		    <td>56.38</td>
		    <td>83.50</td>
		  </tr>
		  <tr>
		    <td class="model-name">LTX-Video</td>
		    <td>97.44</td>
		    <td>95.82</td>
		    <td>99.60</td>
		    <td>4.97</td>
		    <td>43.62</td>
		    <td>61.85</td>
		    <td>100.00</td>
		  </tr>
		  <tr>
		    <td class="model-name">HunyuanVideo</td>
		    <td>91.47</td>
		    <td>95.82</td>
		    <td>99.20</td>
		    <td>63.00</td>
		    <td>48.67</td>
		    <td>65.85</td>
		    <td>45.00</td>
		  </tr>
		  <tr>
		    <td colspan="8" class="section-header">Commercial video generation model</td>
		  </tr>
		  <tr>
		    <td class="model-name">Kling</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		  </tr>
		  <tr>
		    <td class="model-name">Hailuo</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		  </tr>
		  <tr>
		    <td class="model-name">Sora</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		  </tr>
		  <tr>
		    <td colspan="8" class="section-header">Our model</td>
		  </tr>
		  <tr>
		    <td class="model-name"><strong>Medical Sora (ours)</strong></td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		    <td>-</td>
		  </tr>
		</table>
	</div>
</div>

<div class="container pt-5 mt-5 shadow-lg p-5 mb-5 bg-white rounded">
	<h2 id="Demo" style="text-align: center;">Demo</h2>

	<div class="highlight">
        	üîä The demo space is still under construction. It cannot be clicked to use.
    	</div>
	<br>
	
	<center>
	<iframe
            src="https://wangrongsheng-medical-sora-demo.hf.space/"
            frameborder="0"
            width="1200"
            height="618"
        ></iframe></center>
</div>

<div class="container pt-5 mt-5 shadow-lg p-5 mb-5 bg-white rounded">
	<h2 style="text-align: center;">Citation</h2>
	<p>If you found our work useful in your research, please consider starring ‚≠ê us on GitHub and citing üìö us in your research!</p>
	<pre><code>
	bib is here.
	</code></pre>
</div>

<div class="container pt-5 mt-5 shadow-lg p-5 mb-5 bg-white rounded">
	<h2 style="text-align: center;">Acknowledgement</h2>
	<p>This website is adapted from <a href="https://github.com/FunAudioLLM/FunAudioLLM.github.io">FunAudioLLM</a>.</p>
	<center><script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=68719b&w=200&t=tt&d=T8MQxvWXD5mumFzJAoJO9UTxzAT7AXfP5x3pTRavo58&co=ffffff&ct=211717'></script></center>
</div>

</article>
</main>
</div>

<script>
    !
    function() {
        function n(n, e, t) {
            return n.getAttribute(e) || t
        }
        function e(n) {
            return document.getElementsByTagName(n)
        }
        function t() {
            var t = e("script"),
            o = t.length,
            i = t[o - 1];
            return {
                l: o,
                z: n(i, "zIndex", -1),
                o: n(i, "opacity", .5),
                c: n(i, "color", "0,0,0"),
                n: n(i, "count", 99)
            }
        }
        function o() {
            a = m.width = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth,
            c = m.height = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight
        }
        function i() {
            r.clearRect(0, 0, a, c);
            var n, e, t, o, m, l;
            s.forEach(function(i, x) {
                for (i.x += i.xa, i.y += i.ya, i.xa *= i.x > a || i.x < 0 ? -1 : 1, i.ya *= i.y > c || i.y < 0 ? -1 : 1, r.fillRect(i.x - .5, i.y - .5, 1, 1), e = x + 1; e < u.length; e++) n = u[e],
                null !== n.x && null !== n.y && (o = i.x - n.x, m = i.y - n.y, l = o * o + m * m, l < n.max && (n === y && l >= n.max / 2 && (i.x -= .03 * o, i.y -= .03 * m), t = (n.max - l) / n.max, r.beginPath(), r.lineWidth = t / 2, r.strokeStyle = "rgba(" + d.c + "," + (t + .2) + ")", r.moveTo(i.x, i.y), r.lineTo(n.x, n.y), r.stroke()))
            }),
            x(i)
        }
        var a, c, u, m = document.createElement("canvas"),
        d = t(),
        l = "c_n" + d.l,
        r = m.getContext("2d"),
        x = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame ||
        function(n) {
            window.setTimeout(n, 1e3 / 45)
        },
        w = Math.random,
        y = {
            x: null,
            y: null,
            max: 2e4
        };
        m.id = l,
        m.style.cssText = "position:fixed;top:0;left:0;z-index:" + d.z + ";opacity:" + d.o,
        e("body")[0].appendChild(m),
        o(),
        window.onresize = o,
        window.onmousemove = function(n) {
            n = n || window.event,
            y.x = n.clientX,
            y.y = n.clientY
        },
        window.onmouseout = function() {
            y.x = null,
            y.y = null
        };
        for (var s = [], f = 0; d.n > f; f++) {
            var h = w() * a,
            g = w() * c,
            v = 2 * w() - 1,
            p = 2 * w() - 1;
            s.push({
                x: h,
                y: g,
                xa: v,
                ya: p,
                max: 6e3
            })
        }
        u = s.concat([y]),
        setTimeout(function() {
            i()
        },
        100)
    } ();
</script>

</body>

</script>
</html>
